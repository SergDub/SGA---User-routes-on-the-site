{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dde482a4-47d8-413c-b8ac-2199ccc333e1",
      "metadata": {
        "id": "dde482a4-47d8-413c-b8ac-2199ccc333e1"
      },
      "source": [
        "# User routes on the site\n",
        "### Part 1. Spark DF solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13dd0469-09e8-477f-be32-d1575274c163",
      "metadata": {
        "id": "13dd0469-09e8-477f-be32-d1575274c163",
        "outputId": "efef191d-2cd9-438c-fc6a-0d67b5164edf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "2024-10-24 10:00:10,160 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- session_id: integer (nullable = true)\n",
            " |-- event_type: string (nullable = true)\n",
            " |-- event_page: string (nullable = true)\n",
            " |-- timestamp: integer (nullable = true)\n",
            "\n",
            "Original data:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----------+------------+----------+----------+\n",
            "|user_id|session_id|  event_type|event_page| timestamp|\n",
            "+-------+----------+------------+----------+----------+\n",
            "|    562|       507|        page|      main|1695584127|\n",
            "|    562|       507|       event|      main|1695584134|\n",
            "|    562|       507|       event|      main|1695584144|\n",
            "|    562|       507|       event|      main|1695584147|\n",
            "|    562|       507|wNaxLlerrorU|      main|1695584154|\n",
            "+-------+----------+------------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000000\n"
          ]
        }
      ],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql import Window\n",
        "import numpy as np\n",
        "import json\n",
        "from pyspark.sql.types import ArrayType, StringType\n",
        "import sys\n",
        "import os\n",
        "np.random.seed(0)\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Clickstream_DF\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"OFF\")\n",
        "\n",
        "# Loading data from HDFS\n",
        "clickstream_data = spark.read.csv(\"hdfs:///data/clickstream.csv\", header=True, inferSchema=True, sep='\\t')\n",
        "\n",
        "# Displaying the schema of the data\n",
        "clickstream_data.printSchema()\n",
        "\n",
        "# Displaying original data\n",
        "print(\"Original data:\")\n",
        "clickstream_data.show(5)\n",
        "print(clickstream_data.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e405152-e9b2-4238-8679-d21fdd2fc0e7",
      "metadata": {
        "id": "1e405152-e9b2-4238-8679-d21fdd2fc0e7",
        "outputId": "2e3ed3bd-1e34-4358-a81c-3503a4b410f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Searching for rows with errors\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----------+-----------------+----------+----------+\n",
            "|user_id|session_id|       event_type|event_page| timestamp|\n",
            "+-------+----------+-----------------+----------+----------+\n",
            "|    562|       507|     wNaxLlerrorU|      main|1695584154|\n",
            "|   4567|       514|    mAXExoCXerror|      main|1695584351|\n",
            "|    461|       174|uvjferrorYYwYlubX|  internet|1695584529|\n",
            "|    844|       258|kfIpzqTUaerrorSQD|      main|1695584652|\n",
            "|    461|       174|       iVerrornrA|      news|1695584698|\n",
            "+-------+----------+-----------------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Finding the minimum timestamp of errors for each session (user_id + session_id)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----------+-------------------+\n",
            "|user_id|session_id|min_error_timestamp|\n",
            "+-------+----------+-------------------+\n",
            "|   3513|        68|         1695623875|\n",
            "|   4332|       766|         1695633583|\n",
            "|   4757|       611|         1695653221|\n",
            "|   2009|       827|         1695747863|\n",
            "|   1731|       193|         1695798006|\n",
            "+-------+----------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Joining with main data and filtering events after the first error\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----------+------------+----------+----------+-------------------+\n",
            "|user_id|session_id|  event_type|event_page| timestamp|min_error_timestamp|\n",
            "+-------+----------+------------+----------+----------+-------------------+\n",
            "|    562|       507|        page|      main|1695584127|         1695584154|\n",
            "|    562|       507|       event|      main|1695584134|         1695584154|\n",
            "|    562|       507|       event|      main|1695584144|         1695584154|\n",
            "|    562|       507|       event|      main|1695584147|         1695584154|\n",
            "|    562|       507|wNaxLlerrorU|      main|1695584154|         1695584154|\n",
            "+-------+----------+------------+----------+----------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000000\n",
            "Data after filtering out rows after the first error:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----------+----------+----------+----------+\n",
            "|user_id|session_id|event_type|event_page| timestamp|\n",
            "+-------+----------+----------+----------+----------+\n",
            "|   1889|       140|      page|      main|1695614937|\n",
            "|   1889|       140|      page|  internet|1695614956|\n",
            "|   1889|       140|     event|  internet|1695614971|\n",
            "|   1889|       140|      page|   archive|1695614980|\n",
            "|   1889|       140|     event|   archive|1695615006|\n",
            "+-------+----------+----------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 33:=============================>                            (3 + 2) / 6]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "698547\n",
            "Filtering only events of type 'page'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----------+----------+----------+----------+\n",
            "|user_id|session_id|event_type|event_page| timestamp|\n",
            "+-------+----------+----------+----------+----------+\n",
            "|   1889|       140|      page|      main|1695614937|\n",
            "|   1889|       140|      page|  internet|1695614956|\n",
            "|   1889|       140|      page|   archive|1695614980|\n",
            "|   1889|       140|      page|      main|1695615032|\n",
            "|   3513|        68|      page|      main|1695619122|\n",
            "+-------+----------+----------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Grouping events by user_id and session_id, collecting pages in the correct order...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|user_id|session_id|page_sequence                                                                                                                                           |\n",
            "+-------+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|0      |874       |[main, rabota, online]                                                                                                                                  |\n",
            "|0      |898       |[main, news, tariffs, rabota, bonus, tariffs, bonus, internet, news, tariffs, online, archive]                                                          |\n",
            "|0      |901       |[main, internet, bonus, main, internet, vklad, main, rabota, online, main, internet, rabota, tariffs, bonus, online, rabota, vklad, news, bonus, rabota]|\n",
            "|1      |954       |[main, bonus]                                                                                                                                           |\n",
            "|1      |979       |[main, rabota, archive, bonus, rabota]                                                                                                                  |\n",
            "+-------+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Creating string routes through '-' for each session (user_id + session_id)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------+\n",
            "|user_id|session_id|page_sequence                                                                                                                                           |route                                                                                                                              |\n",
            "+-------+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------+\n",
            "|0      |874       |[main, rabota, online]                                                                                                                                  |main-rabota-online                                                                                                                 |\n",
            "|0      |898       |[main, news, tariffs, rabota, bonus, tariffs, bonus, internet, news, tariffs, online, archive]                                                          |main-news-tariffs-rabota-bonus-tariffs-bonus-internet-news-tariffs-online-archive                                                  |\n",
            "|0      |901       |[main, internet, bonus, main, internet, vklad, main, rabota, online, main, internet, rabota, tariffs, bonus, online, rabota, vklad, news, bonus, rabota]|main-internet-bonus-main-internet-vklad-main-rabota-online-main-internet-rabota-tariffs-bonus-online-rabota-vklad-news-bonus-rabota|\n",
            "|1      |954       |[main, bonus]                                                                                                                                           |main-bonus                                                                                                                         |\n",
            "|1      |979       |[main, rabota, archive, bonus, rabota]                                                                                                                  |main-rabota-archive-bonus-rabota                                                                                                   |\n",
            "+-------+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Counting sessions for each unique route\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|route                                                                                                                                                            |count|\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|main-archive-internet-archive                                                                                                                                    |21   |\n",
            "|main-archive-vklad-internet-main-archive-tariffs-rabota-bonus-archive-digital-rabota-news-internet-archive-main-news-main-news-bonus-vklad-internet-tariffs-bonus|1    |\n",
            "|main-internet-bonus-main                                                                                                                                         |8    |\n",
            "|main-online-tariffs-online-vklad                                                                                                                                 |1    |\n",
            "|main-archive-bonus-news                                                                                                                                          |11   |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "Sorting by count and selecting top-30 routes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 72:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------+-----+\n",
            "|route                |count|\n",
            "+---------------------+-----+\n",
            "|main                 |8184 |\n",
            "|main-archive         |1113 |\n",
            "|main-rabota          |1047 |\n",
            "|main-internet        |897  |\n",
            "|main-bonus           |870  |\n",
            "|main-news            |769  |\n",
            "|main-tariffs         |677  |\n",
            "|main-online          |587  |\n",
            "|main-vklad           |518  |\n",
            "|main-rabota-archive  |170  |\n",
            "|main-archive-rabota  |167  |\n",
            "|main-bonus-archive   |143  |\n",
            "|main-rabota-bonus    |139  |\n",
            "|main-bonus-rabota    |135  |\n",
            "|main-news-rabota     |135  |\n",
            "|main-archive-internet|132  |\n",
            "|main-rabota-news     |130  |\n",
            "|main-internet-rabota |129  |\n",
            "|main-archive-news    |126  |\n",
            "|main-rabota-internet |124  |\n",
            "|main-internet-archive|123  |\n",
            "|main-archive-bonus   |117  |\n",
            "|main-internet-bonus  |115  |\n",
            "|main-tariffs-internet|114  |\n",
            "|main-news-archive    |113  |\n",
            "|main-news-internet   |109  |\n",
            "|main-archive-tariffs |104  |\n",
            "|main-internet-news   |103  |\n",
            "|main-tariffs-archive |103  |\n",
            "|main-rabota-main     |94   |\n",
            "+---------------------+-----+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Finding rows with errors\n",
        "print(\"Searching for rows with errors\")\n",
        "error_dataframe = clickstream_data.filter(F.col('event_type').rlike(\".*error.*\"))\n",
        "error_dataframe.show(5)\n",
        "\n",
        "# For each combination of user_id and session_id, finding the minimum timestamp of the error\n",
        "print(\"Finding the minimum timestamp of errors for each session (user_id + session_id)...\")\n",
        "error_min_timestamp = error_dataframe.groupBy('user_id', 'session_id').agg(F.min('timestamp').alias('min_error_timestamp'))\n",
        "error_min_timestamp.show(5)\n",
        "\n",
        "# Joining data with clickstream and filter out rows after the first error\n",
        "print(\"Joining with main data and filtering events after the first error\")\n",
        "joined_dataframe = clickstream_data.join(error_min_timestamp, ['user_id', 'session_id'], 'left')\n",
        "joined_dataframe.show(5)\n",
        "print(joined_dataframe.count())\n",
        "\n",
        "# Removing rows that occurred after the first error\n",
        "filtered_dataframe = joined_dataframe.filter(\n",
        "    (F.col('min_error_timestamp').isNull()) | (F.col('timestamp') < F.col('min_error_timestamp'))\n",
        ")\n",
        "filtered_dataframe = filtered_dataframe.drop('min_error_timestamp')\n",
        "\n",
        "print(\"Data after filtering out rows after the first error:\")\n",
        "filtered_dataframe.show(5)\n",
        "print(filtered_dataframe.count())\n",
        "\n",
        "# Keeping only events of type 'page' as they are important for route construction\n",
        "print(\"Filtering only events of type 'page'\")\n",
        "page_events_dataframe = filtered_dataframe.filter(F.col('event_type') == 'page')\n",
        "page_events_dataframe.show(5)\n",
        "\n",
        "# Function to remove consecutive duplicates\n",
        "def remove_consecutive_duplicates(pages):\n",
        "    if not pages:\n",
        "        return pages\n",
        "    result = [pages[0]]\n",
        "    for page in pages[1:]:\n",
        "        if page != result[-1]:\n",
        "            result.append(page)\n",
        "    return result\n",
        "\n",
        "# Registering UDF for using in Spark\n",
        "remove_consecutive_duplicates_udf = F.udf(remove_consecutive_duplicates, ArrayType(StringType()))\n",
        "\n",
        "# Groupping events by user_id and session_id and ordering by timestamp\n",
        "print(\"Grouping events by user_id and session_id, collecting pages in the correct order...\")\n",
        "window_specification = Window.partitionBy('user_id', 'session_id').orderBy('timestamp')\n",
        "\n",
        "# Aggregating all pages for each session in the correct order\n",
        "page_sequences_dataframe = page_events_dataframe \\\n",
        "    .withColumn('ordered_pages', F.collect_list('event_page').over(window_specification)) \\\n",
        "    .groupBy('user_id', 'session_id') \\\n",
        "    .agg(F.max('ordered_pages').alias('page_sequence'))\n",
        "\n",
        "# Removing consecutive duplicates\n",
        "page_sequences_dataframe = page_sequences_dataframe.withColumn('page_sequence', remove_consecutive_duplicates_udf(F.col('page_sequence')))\n",
        "page_sequences_dataframe.show(5, truncate=False)\n",
        "\n",
        "# Concatenating the list of pages into a string\n",
        "print(\"Creating string routes through '-' for each session (user_id + session_id)\")\n",
        "page_sequences_dataframe = page_sequences_dataframe.withColumn('route', F.concat_ws(\"-\", F.col('page_sequence')))\n",
        "page_sequences_dataframe.show(5, truncate=False)\n",
        "\n",
        "# Counting the number of unique routes\n",
        "print(\"Counting sessions for each unique route\")\n",
        "route_counts_dataframe = page_sequences_dataframe.groupBy('route').count()\n",
        "route_counts_dataframe.show(5, truncate=False)\n",
        "\n",
        "# Sorting routes by descending frequency and select top-30\n",
        "print(\"Sorting by count and selecting top-30 routes\")\n",
        "top_routes_dataframe = route_counts_dataframe.orderBy(F.desc('count')).limit(30)\n",
        "top_routes_dataframe.show(30, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b06c5432-5d58-4c3d-963b-f1a650b39b19",
      "metadata": {
        "id": "b06c5432-5d58-4c3d-963b-f1a650b39b19",
        "outputId": "1cbbf46e-9b17-44f8-ecf9-66b2ea8c01ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing to the CSV file: hdfs:///output/top_routes_df.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Writing to the file on HDFS\n",
        "output_path = \"hdfs:///output/top_routes_df.csv\"\n",
        "print(f\"Writing to the CSV file: {output_path}\")\n",
        "\n",
        "top_routes_dataframe.write.mode('overwrite').csv(output_path, sep='\\t', header=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c1585e7-27f0-4176-b150-0733bba31420",
      "metadata": {
        "id": "4c1585e7-27f0-4176-b150-0733bba31420",
        "outputId": "08d0d7c5-6a88-42cc-bb2f-af5d56de9cdb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "top_routes_pd = top_routes_dataframe.toPandas()\n",
        "output_csv_path = \"top_routes_df.csv\"\n",
        "\n",
        "# Saving to file with tab delimiter\n",
        "top_routes_pd.to_csv(output_csv_path, sep='\\t', index=False, header=True)\n",
        "spark.stop()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e006c727-49ae-421c-aafe-792f4f19df8f",
      "metadata": {
        "id": "e006c727-49ae-421c-aafe-792f4f19df8f"
      },
      "source": [
        "### Part 2. Spark SQL solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e6bc158-de98-4bea-8129-5e5b296c1975",
      "metadata": {
        "id": "7e6bc158-de98-4bea-8129-5e5b296c1975",
        "outputId": "dea50411-4994-401a-c3b2-cdf68196480b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original data:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----------+------------+----------+----------+\n",
            "|user_id|session_id|  event_type|event_page| timestamp|\n",
            "+-------+----------+------------+----------+----------+\n",
            "|    562|       507|        page|      main|1695584127|\n",
            "|    562|       507|       event|      main|1695584134|\n",
            "|    562|       507|       event|      main|1695584144|\n",
            "|    562|       507|       event|      main|1695584147|\n",
            "|    562|       507|wNaxLlerrorU|      main|1695584154|\n",
            "+-------+----------+------------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Clickstream_SQL\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "#spark.sparkContext.setLogLevel(\"WARN\")\n",
        "spark.sparkContext.setLogLevel(\"OFF\")\n",
        "\n",
        "# Loading data from HDFS\n",
        "clickstream_data = spark.read.csv(\"hdfs:///data/clickstream.csv\", header=True, inferSchema=True, sep='\\t')\n",
        "\n",
        "print(\"Original data:\")\n",
        "clickstream_data.show(5)\n",
        "\n",
        "clickstream_data.createOrReplaceTempView(\"clickstream\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63ee73ee-3736-432b-bfe2-e937faaaf495",
      "metadata": {
        "id": "63ee73ee-3736-432b-bfe2-e937faaaf495",
        "outputId": "bbd65b20-932c-4a85-9cb9-edc8b8fcbef0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data after query 1:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----------+----------+\n",
            "|user_id|session_id|event_page|\n",
            "+-------+----------+----------+\n",
            "|      0|       874|      main|\n",
            "|      0|       874|    rabota|\n",
            "|      0|       874|    online|\n",
            "|      0|       898|      main|\n",
            "|      0|       898|      news|\n",
            "+-------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Top-30 unique routes:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------+-----+\n",
            "|route                |count|\n",
            "+---------------------+-----+\n",
            "|main                 |8184 |\n",
            "|main-archive         |1113 |\n",
            "|main-rabota          |1047 |\n",
            "|main-internet        |897  |\n",
            "|main-bonus           |870  |\n",
            "|main-news            |769  |\n",
            "|main-tariffs         |677  |\n",
            "|main-online          |587  |\n",
            "|main-vklad           |518  |\n",
            "|main-rabota-archive  |170  |\n",
            "|main-archive-rabota  |167  |\n",
            "|main-bonus-archive   |143  |\n",
            "|main-rabota-bonus    |139  |\n",
            "|main-bonus-rabota    |135  |\n",
            "|main-news-rabota     |135  |\n",
            "|main-archive-internet|132  |\n",
            "|main-rabota-news     |130  |\n",
            "|main-internet-rabota |129  |\n",
            "|main-archive-news    |126  |\n",
            "|main-rabota-internet |124  |\n",
            "|main-internet-archive|122  |\n",
            "|main-archive-bonus   |117  |\n",
            "|main-internet-bonus  |115  |\n",
            "|main-tariffs-internet|114  |\n",
            "|main-news-archive    |113  |\n",
            "|main-news-internet   |109  |\n",
            "|main-archive-tariffs |104  |\n",
            "|main-internet-news   |103  |\n",
            "|main-tariffs-archive |103  |\n",
            "|main-rabota-main     |94   |\n",
            "+---------------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#  Finding rows with errors, minimum error timestamps for each session, and filtering them\n",
        "query1 = \"\"\"\n",
        "WITH error_min_timestamp AS (\n",
        "    SELECT user_id, session_id, MIN(timestamp) AS min_error_timestamp\n",
        "    FROM clickstream\n",
        "    WHERE event_type LIKE '%error%'\n",
        "    GROUP BY user_id, session_id\n",
        "),\n",
        "filtered_data AS (\n",
        "    SELECT c.*\n",
        "    FROM clickstream c\n",
        "    LEFT JOIN error_min_timestamp e\n",
        "    ON c.user_id = e.user_id AND c.session_id = e.session_id\n",
        "    WHERE e.min_error_timestamp IS NULL OR c.timestamp < e.min_error_timestamp\n",
        "),\n",
        "page_events AS (\n",
        "    SELECT\n",
        "        user_id,\n",
        "        session_id,\n",
        "        event_page,\n",
        "        LAG(event_page, 1) OVER (PARTITION BY user_id, session_id ORDER BY timestamp) AS previous_page\n",
        "    FROM filtered_data\n",
        "    WHERE event_type = 'page'\n",
        "),\n",
        "unique_page_events AS (\n",
        "    SELECT user_id, session_id, event_page\n",
        "    FROM page_events\n",
        "    WHERE event_page != previous_page OR previous_page IS NULL\n",
        ")\n",
        "SELECT user_id, session_id, event_page\n",
        "FROM unique_page_events\n",
        "\"\"\"\n",
        "\n",
        "# Executing the query\n",
        "page_events_dataframe = spark.sql(query1)\n",
        "\n",
        "print(\"Data after query 1:\")\n",
        "page_events_dataframe.show(5)\n",
        "\n",
        "page_events_dataframe.createOrReplaceTempView(\"page_events\")\n",
        "\n",
        "# Collecting the list of pages for each session and counting unique routes\n",
        "query2 = \"\"\"\n",
        "WITH page_sequences AS (\n",
        "    SELECT user_id, session_id, COLLECT_LIST(event_page) AS page_sequence\n",
        "    FROM page_events\n",
        "    GROUP BY user_id, session_id\n",
        "),\n",
        "route_sequences AS (\n",
        "    SELECT user_id, session_id, CONCAT_WS('-', page_sequence) AS route\n",
        "    FROM page_sequences\n",
        ")\n",
        "SELECT route, COUNT(*) AS count\n",
        "FROM route_sequences\n",
        "GROUP BY route\n",
        "ORDER BY count DESC\n",
        "LIMIT 30\n",
        "\"\"\"\n",
        "\n",
        "# Executing the query\n",
        "top_routes_dataframe = spark.sql(query2)\n",
        "\n",
        "print(\"Top-30 unique routes:\")\n",
        "top_routes_dataframe.show(30, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7dbbb32-ce45-46dc-8d42-fd33fb3d8f72",
      "metadata": {
        "id": "e7dbbb32-ce45-46dc-8d42-fd33fb3d8f72",
        "outputId": "f1edcbd1-f788-47d0-8f92-a05b38eb2ecb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing to the file: hdfs:///output/top_routes_sql.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Writing to the file on HDFS\n",
        "output_path = \"hdfs:///output/top_routes_sql.csv\"\n",
        "print(f\"Writing to the file: {output_path}\")\n",
        "top_routes_dataframe.write.mode('overwrite').csv(output_path, sep='\\t', header=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7ef4c27-305a-4927-96c7-50e5e4958f81",
      "metadata": {
        "id": "c7ef4c27-305a-4927-96c7-50e5e4958f81",
        "outputId": "d14459bb-2369-4447-a9b0-b7d22f23411f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "top_routes_pd = top_routes_dataframe.toPandas()\n",
        "output_csv_path = \"top_routes_sql.csv\"\n",
        "\n",
        "top_routes_pd.to_csv(output_csv_path, sep='\\t', index=False, header=True)\n",
        "spark.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "659ac2bd-2259-4904-a4b6-ac370ed15f60",
      "metadata": {
        "id": "659ac2bd-2259-4904-a4b6-ac370ed15f60"
      },
      "source": [
        "### Part 3. Spark RDD solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4fc5d91-4867-4d8f-9df8-fd9d8072f89f",
      "metadata": {
        "id": "e4fc5d91-4867-4d8f-9df8-fd9d8072f89f",
        "outputId": "ce9bfab1-2850-4f89-87ea-d67f28426ff7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "2024-10-24 11:03:10,516 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from HDFS...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of data rows: 1000000\n"
          ]
        }
      ],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import pyspark\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "spark_context = SparkContext(appName=\"Clickstream_RDD\")\n",
        "spark = SparkSession.builder.appName(\"Clickstream_RDD\").getOrCreate()\n",
        "\n",
        "spark_context.setLogLevel(\"OFF\")\n",
        "\n",
        "# Loading data from HDFS\n",
        "print(\"Loading data from HDFS\")\n",
        "clickstream_rdd = spark_context.textFile(\"hdfs:///data/clickstream.csv\").map(lambda line: line.split('\\t'))\n",
        "header = clickstream_rdd.first()\n",
        "clickstream_rdd = clickstream_rdd.filter(lambda row: row != header)\n",
        "\n",
        "print(f\"Total number of data rows: {clickstream_rdd.count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "514310b9-3693-48cf-af31-8742883c5b64",
      "metadata": {
        "id": "514310b9-3693-48cf-af31-8742883c5b64",
        "outputId": "4cf64d5f-43d6-448b-ef88-77ffe4d2715d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtering rows with errors\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Errors found: 20899\n",
            "Finding the minimum error timestamp for each session\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique user_id and session_id combinations with errors: 14569\n",
            "Joining data and filtering events after the first error\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows after filtering: 698547\n",
            "Filtering only 'page' events\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of 'page' events: 294335\n",
            "Grouping events by user_id and session_id\n",
            "Removing consecutive duplicate pages\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique routes after removing duplicates: 48522\n",
            "Counting the number of sessions for each unique route\n",
            "Sorting routes by frequency and selecting the top 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 30 routes:\n",
            "('main', 8184)\n",
            "('main-archive', 1113)\n",
            "('main-rabota', 1047)\n",
            "('main-internet', 897)\n",
            "('main-bonus', 870)\n",
            "('main-news', 769)\n",
            "('main-tariffs', 677)\n",
            "('main-online', 587)\n",
            "('main-vklad', 518)\n",
            "('main-rabota-archive', 170)\n",
            "('main-archive-rabota', 167)\n",
            "('main-bonus-archive', 143)\n",
            "('main-rabota-bonus', 139)\n",
            "('main-news-rabota', 135)\n",
            "('main-bonus-rabota', 135)\n",
            "('main-archive-internet', 132)\n",
            "('main-rabota-news', 130)\n",
            "('main-internet-rabota', 129)\n",
            "('main-archive-news', 126)\n",
            "('main-rabota-internet', 124)\n",
            "('main-internet-archive', 123)\n",
            "('main-archive-bonus', 117)\n",
            "('main-internet-bonus', 115)\n",
            "('main-tariffs-internet', 114)\n",
            "('main-news-archive', 113)\n",
            "('main-news-internet', 109)\n",
            "('main-archive-tariffs', 104)\n",
            "('main-internet-news', 103)\n",
            "('main-tariffs-archive', 103)\n",
            "('main-rabota-main', 94)\n"
          ]
        }
      ],
      "source": [
        "# Filtering rows with errors\n",
        "print(\"Filtering rows with errors\")\n",
        "error_rdd = clickstream_rdd.filter(lambda row: 'error' in row[2])\n",
        "print(f\"Errors found: {error_rdd.count()}\")\n",
        "\n",
        "# Finding the minimum error timestamp\n",
        "print(\"Finding the minimum error timestamp for each session\")\n",
        "error_min_timestamp = error_rdd.map(lambda row: ((row[0], row[1]), int(row[4]))) \\\n",
        "                                .reduceByKey(min)\n",
        "print(f\"Number of unique user_id and session_id combinations with errors: {error_min_timestamp.count()}\")\n",
        "\n",
        "# Joining data and filtering events after the first error\n",
        "print(\"Joining data and filtering events after the first error\")\n",
        "clickstream_with_errors = clickstream_rdd.map(lambda row: ((row[0], row[1]), (row[2], row[3], int(row[4]))))  # (user_id, session_id) -> (event_type, event_page, timestamp)\n",
        "joined_rdd = clickstream_with_errors.leftOuterJoin(error_min_timestamp)\n",
        "\n",
        "# Removing rows that occurred after the first error\n",
        "filtered_rdd = joined_rdd.filter(lambda x: x[1][1] is None or x[1][0][2] < x[1][1])  # If min_error_timestamp is None or timestamp < min_error_timestamp\n",
        "print(f\"Number of rows after filtering: {filtered_rdd.count()}\")\n",
        "\n",
        "#  Keeping only 'page' events\n",
        "print(\"Filtering only 'page' events\")\n",
        "page_events_rdd = filtered_rdd.filter(lambda x: x[1][0][0] == 'page')\n",
        "print(f\"Number of 'page' events: {page_events_rdd.count()}\")\n",
        "\n",
        "# Grouping events by user_id and session_id\n",
        "print(\"Grouping events by user_id and session_id\")\n",
        "page_sequences = page_events_rdd.map(lambda x: ((x[0][0], x[0][1]), x[1][0][1]))  # ((user_id, session_id), event_page)\n",
        "grouped_rdd = page_sequences.groupByKey()\n",
        "\n",
        "# Removing consecutive duplicates\n",
        "print(\"Removing consecutive duplicate pages\")\n",
        "def remove_consecutive_duplicates(pages):\n",
        "    if not pages:\n",
        "        return pages\n",
        "    result = [pages[0]]\n",
        "    for page in pages[1:]:\n",
        "        if page != result[-1]:\n",
        "            result.append(page)\n",
        "    return result\n",
        "\n",
        "# Applying the function to remove duplicates and create routes\n",
        "routes_rdd = grouped_rdd.mapValues(lambda pages: '-'.join(remove_consecutive_duplicates(list(pages))))\n",
        "print(f\"Number of unique routes after removing duplicates: {routes_rdd.count()}\")\n",
        "\n",
        "# Counting the number of unique routes\n",
        "print(\"Counting the number of sessions for each unique route\")\n",
        "route_counts = routes_rdd.map(lambda x: (x[1], 1)).reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "# Sorting routes by descending frequency and selecting the top 30\n",
        "print(\"Sorting routes by frequency and selecting the top 30\")\n",
        "top_routes = route_counts.takeOrdered(30, key=lambda x: -x[1])\n",
        "\n",
        "print(\"Top 30 routes:\")\n",
        "for route in top_routes:\n",
        "    print(route)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6ccda09-b4d6-480d-925b-54646107849e",
      "metadata": {
        "id": "a6ccda09-b4d6-480d-925b-54646107849e",
        "outputId": "a9c39e2e-4935-4096-d492-5f7f7c046c47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing to the file: hdfs:///output/top_routes_RDD.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Writing to the file\n",
        "from pyspark.sql import Row\n",
        "\n",
        "top_routes_rows = [Row(route=route[0], count=route[1]) for route in top_routes]\n",
        "top_routes_dataframe = spark.createDataFrame(top_routes_rows)\n",
        "\n",
        "output_path = \"hdfs:///output/top_routes_RDD.csv\"\n",
        "print(f\"Writing to the file: {output_path}\")\n",
        "top_routes_dataframe.write.mode(\"overwrite\").csv(output_path, sep='\\t', header=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68a6ca90-872e-4aae-9cdb-3cc841a7d12e",
      "metadata": {
        "tags": [],
        "id": "68a6ca90-872e-4aae-9cdb-3cc841a7d12e",
        "outputId": "8f1841cb-4ab5-4336-ab8b-b5f12d38f64a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "top_routes_pd = top_routes_dataframe.toPandas()\n",
        "output_csv_path = \"top_routes_RDD.csv\"\n",
        "\n",
        "top_routes_pd.to_csv(output_csv_path, sep='\\t', index=False, header=True)\n",
        "\n",
        "spark.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "681d0a65-a9fa-4d35-a9cc-cb19ecd3c267",
      "metadata": {
        "id": "681d0a65-a9fa-4d35-a9cc-cb19ecd3c267"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}